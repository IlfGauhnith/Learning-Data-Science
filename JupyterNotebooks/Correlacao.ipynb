{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import re"
      ],
      "metadata": {
        "id": "18RimmkXmq1b"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "mzDq2LuhmBmp"
      },
      "outputs": [],
      "source": [
        "def separate_city_team_nhl(row):\n",
        "  composite_team_name = ['Maple Leafs', 'Red Wings', 'Blue Jackets', 'Golden Knights']\n",
        "\n",
        "  if any(team_name in row['team'] for team_name in composite_team_name):\n",
        "      row['team'] = row['team'].split(\" \")[-2] + \" \" + row['team'].split(\" \")[-1] \n",
        "  else:\n",
        "      row['team'] = row['team'].split(\" \")[-1]\n",
        "\n",
        "  return row\n",
        "\n",
        "\n",
        "def separate_city_team_nba(row):\n",
        "  composite_team_name = ['Trail Blazers']\n",
        "\n",
        "  if any(team_name in row['team'] for team_name in composite_team_name):\n",
        "      row['team'] = row['team'].split(\" \")[-2] + \" \" + row['team'].split(\" \")[-1] \n",
        "  else:\n",
        "      row['team'] = row['team'].split(\" \")[-1]\n",
        "\n",
        "  return row\n",
        "\n",
        "\n",
        "def separate_city_team_mlb(row):\n",
        "  composite_team_name = ['Red Sox', 'Blue Jays', 'White Sox']\n",
        "\n",
        "  if any(team_name in row['team'] for team_name in composite_team_name):\n",
        "      row['team'] = row['team'].split(\" \")[-2] + \" \" + row['team'].split(\" \")[-1] \n",
        "  else:\n",
        "      row['team'] = row['team'].split(\" \")[-1]\n",
        "\n",
        "  return row\n",
        "\n",
        "def separate_city_team_nfl(row):\n",
        "  row['team'] = row['team'].split(\" \")[-1]\n",
        "\n",
        "  return row\n",
        "\n",
        "\n",
        "def group_win_loss_ratio(group):\n",
        "  avg_ratio = np.nanmean(group['Win ratio'])\n",
        "\n",
        "  group['Win ratio'] = avg_ratio\n",
        "  group['Population'] = group['Population']\n",
        "\n",
        "  return group"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_nhl_df():\n",
        "  divisions = ['Atlantic Division', 'Metropolitan Division', 'Central Division', 'Pacific Division']\n",
        "  nhl_df = pd.read_csv(\"/content/nhl.csv\")\n",
        "  nhl_df = nhl_df[ pd.to_datetime(nhl_df['year'], format='%Y') == '2018']\n",
        "  nhl_df = nhl_df[ ~nhl_df['team'].isin(divisions) ]\n",
        "  nhl_df = nhl_df[['team', 'L', 'W']]\n",
        "  nhl_df['team'] = nhl_df['team'].replace(to_replace='\\*', value='', regex=True)\n",
        "  nhl_df = nhl_df.apply(separate_city_team_nhl, axis=1)\n",
        "  nhl_df = nhl_df.reset_index(drop=True)\n",
        "\n",
        "  cities = pd.read_html(\"/content/wikipedia_data.html\")[1]\n",
        "  cities = cities.iloc[:-1,[0,3,5,6,7,8]]\n",
        "  cities = cities.replace(to_replace=['—', '\\[.*\\]'], value='', regex=True)\n",
        "  cities = cities.rename(columns={'Population (2016 est.)[8]': 'Population'})\n",
        "  cities = cities[['Metropolitan area', 'Population', 'NHL']]\n",
        "  cities = cities[cities['NHL'] != '']\n",
        "\n",
        "  multivalued_team_name = ['Rangers Islanders Devils', 'Kings Ducks']\n",
        "\n",
        "  cities['NHL'][cities['NHL'].isin(multivalued_team_name)] = cities['NHL'][cities['NHL'].isin(multivalued_team_name)].str.split(\" \")\n",
        "  cities = cities.explode('NHL')\n",
        "  cities = cities.reset_index(drop=True)\n",
        "\n",
        "  cities_teams_nhl = pd.merge(cities, nhl_df, how='inner', left_on='NHL', right_on='team')\n",
        "  cities_teams_nhl = cities_teams_nhl.rename(columns={'L': 'Loss', 'W': 'Wins'})\n",
        "  cities_teams_nhl = cities_teams_nhl.drop(['NHL', 'team'], axis=1)\n",
        "  cities_teams_nhl[['Population', 'Loss', 'Wins']] = cities_teams_nhl[['Population', 'Loss', 'Wins']].apply(pd.to_numeric) \n",
        "  cities_teams_nhl['Win ratio'] = cities_teams_nhl['Wins'] / (cities_teams_nhl['Wins'] + cities_teams_nhl['Loss'])\n",
        "  cities_teams_nhl = cities_teams_nhl.groupby('Metropolitan area').apply(group_win_loss_ratio)\n",
        "  cities_teams_nhl = cities_teams_nhl.drop_duplicates(subset='Metropolitan area', keep='first')\n",
        "  cities_teams_nhl = cities_teams_nhl.sort_values('Metropolitan area')\n",
        "  cities_teams_nhl = cities_teams_nhl.reset_index(drop=True)\n",
        "\n",
        "  return cities_teams_nhl"
      ],
      "metadata": {
        "id": "vFv9stwUnINf"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_nba_df():\n",
        "  cities = pd.read_html(\"/content/wikipedia_data.html\")[1]\n",
        "  cities = cities.iloc[:-1,[0,3,5,6,7,8]]\n",
        "  cities = cities.replace(to_replace=['—', '\\[.*\\]'], value='', regex=True)\n",
        "  cities = cities.rename(columns={'Population (2016 est.)[8]': 'Population'})\n",
        "  cities = cities[['Metropolitan area', 'Population', 'NBA']]\n",
        "  cities = cities[cities['NBA'] != '']\n",
        "\n",
        "  multivalued_team_name = ['Knicks Nets', 'Lakers Clippers']\n",
        "\n",
        "  cities['NBA'][cities['NBA'].isin(multivalued_team_name)] = cities['NBA'][cities['NBA'].isin(multivalued_team_name)].str.split(\" \")\n",
        "  cities = cities.explode('NBA')\n",
        "  cities = cities.reset_index(drop=True)\n",
        "\n",
        "  nba_df = pd.read_csv(\"/content/nba.csv\")\n",
        "  nba_df = nba_df[ pd.to_datetime(nba_df['year'], format='%Y') == '2018']\n",
        "  nba_df = nba_df[['team', 'W', 'L']]\n",
        "  nba_df['team'] = nba_df['team'].replace(to_replace=['\\*', '\\(\\d+\\)'], value='', regex=True)\n",
        "  nba_df['team'] = nba_df['team'].apply(lambda x: x.strip())\n",
        "  nba_df = nba_df.apply(separate_city_team_nba, axis=1)\n",
        "  nba_df = nba_df.reset_index(drop=True)\n",
        "\n",
        "  cities_teams_nba = pd.merge(cities, nba_df, how='inner', left_on='NBA', right_on='team')\n",
        "  cities_teams_nba = cities_teams_nba.rename(columns={'L': 'Loss', 'W': 'Wins'})\n",
        "  cities_teams_nba = cities_teams_nba.drop(['NBA', 'team'], axis=1)\n",
        "  cities_teams_nba[['Population', 'Loss', 'Wins']] = cities_teams_nba[['Population', 'Loss', 'Wins']].apply(pd.to_numeric) \n",
        "  cities_teams_nba['Win ratio'] = cities_teams_nba['Wins'] / (cities_teams_nba['Wins'] + cities_teams_nba['Loss'])\n",
        "  cities_teams_nba = cities_teams_nba.groupby('Metropolitan area').apply(group_win_loss_ratio)\n",
        "  cities_teams_nba = cities_teams_nba.drop_duplicates(subset='Metropolitan area', keep='first')\n",
        "  cities_teams_nba = cities_teams_nba.sort_values('Metropolitan area')\n",
        "  cities_teams_nba = cities_teams_nba.reset_index(drop=True)\n",
        "\n",
        "  return cities_teams_nba"
      ],
      "metadata": {
        "id": "9vYPoHESoNzy"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_mlb_df():\n",
        "  mlb_df=pd.read_csv(\"/content/mlb.csv\")\n",
        "  mlb_df = mlb_df[ pd.to_datetime(mlb_df['year'], format='%Y') == '2018']\n",
        "  mlb_df = mlb_df[['team', 'W', 'L']]\n",
        "  mlb_df['team'] = mlb_df['team'].apply(lambda x: x.strip())\n",
        "  mlb_df = mlb_df.apply(separate_city_team_mlb, axis=1)\n",
        "  mlb_df = mlb_df.reset_index(drop=True)\n",
        "\n",
        "  cities = pd.read_html(\"/content/wikipedia_data.html\")[1]\n",
        "  cities = cities.iloc[:-1,[0,3,5,6,7,8]]\n",
        "  cities = cities.rename(columns={'Population (2016 est.)[8]': 'Population'})\n",
        "  cities = cities[['Metropolitan area', 'Population', 'MLB']]\n",
        "  cities = cities.replace(to_replace=['—', '\\[.*\\]'], value='', regex=True)\n",
        "  cities = cities[cities['MLB'] != '']\n",
        "\n",
        "  multivalued_team_name = ['Yankees Mets', 'Dodgers Angels', 'Giants Athletics', 'Cubs White Sox']\n",
        "\n",
        "  cities['MLB'][cities['MLB'].isin(multivalued_team_name)] = cities['MLB'][cities['MLB'].isin(multivalued_team_name)].str.split(\" \")\n",
        "  cities['MLB'][3] = ['Cubs', 'White Sox']\n",
        "  cities = cities.explode('MLB')\n",
        "  cities['MLB'] = cities['MLB'].apply(lambda x: x.strip())\n",
        "  cities = cities.reset_index(drop=True)\n",
        "\n",
        "  cities_teams_mlb = pd.merge(cities, mlb_df, how='inner', left_on='MLB', right_on='team')\n",
        "  cities_teams_mlb = cities_teams_mlb.rename(columns={'L': 'Loss', 'W': 'Wins'})\n",
        "  cities_teams_mlb = cities_teams_mlb.drop(['MLB', 'team'], axis=1)\n",
        "  cities_teams_mlb[['Population', 'Loss', 'Wins']] = cities_teams_mlb[['Population', 'Loss', 'Wins']].apply(pd.to_numeric) \n",
        "  cities_teams_mlb['Win ratio'] = cities_teams_mlb['Wins'] / (cities_teams_mlb['Wins'] + cities_teams_mlb['Loss'])\n",
        "  cities_teams_mlb = cities_teams_mlb.groupby('Metropolitan area').apply(group_win_loss_ratio)\n",
        "  cities_teams_mlb = cities_teams_mlb.drop_duplicates(subset='Metropolitan area', keep='first')\n",
        "  cities_teams_mlb = cities_teams_mlb.sort_values('Metropolitan area')\n",
        "  cities_teams_mlb = cities_teams_mlb.reset_index(drop=True)\n",
        "\n",
        "  return cities_teams_mlb"
      ],
      "metadata": {
        "id": "SLNiH4AGo9uR"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_nfl_df():\n",
        "  divisions = ['AFC East', 'AFC North', 'AFC South', 'AFC West', 'NFC East', 'NFC North', 'NFC South', 'NFC West']\n",
        "  nfl_df = pd.read_csv(\"/content/nfl.csv\")\n",
        "  nfl_df = nfl_df[ pd.to_datetime(nfl_df['year'], format='%Y') == '2018']\n",
        "  nfl_df = nfl_df[ ~nfl_df['team'].isin(divisions) ]\n",
        "  nfl_df = nfl_df[['team', 'W', 'L']]\n",
        "  nfl_df['team'] = nfl_df['team'].apply(lambda x: x.strip())\n",
        "  nfl_df['team'] = nfl_df['team'].replace(to_replace=['\\*', '\\+'], value='', regex=True)\n",
        "  nfl_df = nfl_df.apply(separate_city_team_nfl, axis=1)\n",
        "  nfl_df = nfl_df.reset_index(drop=True)\n",
        "\n",
        "\n",
        "  multivalued_team_name = ['Giants Jets', 'Rams Chargers', '49ers Raiders']\n",
        "  cities=pd.read_html(\"/content/wikipedia_data.html\")[1]\n",
        "  cities=cities.iloc[:-1,[0,3,5,6,7,8]]\n",
        "  cities = cities.rename(columns={'Population (2016 est.)[8]': 'Population'})\n",
        "  cities = cities[['Metropolitan area', 'Population', 'NFL']]\n",
        "  cities = cities.replace(to_replace=['—', '\\[.*\\]'], value='', regex=True)\n",
        "  cities['NFL'] = cities['NFL'].apply(lambda x: x.strip())\n",
        "  cities = cities[cities['NFL'] != '']\n",
        "  cities['NFL'][cities['NFL'].isin(multivalued_team_name)] = cities['NFL'][cities['NFL'].isin(multivalued_team_name)].str.split(\" \")\n",
        "  cities = cities.explode('NFL')\n",
        "  cities = cities.reset_index(drop=True)\n",
        "\n",
        "  cities_teams_nfl = pd.merge(cities, nfl_df, how='inner', left_on='NFL', right_on='team')\n",
        "  cities_teams_nfl = cities_teams_nfl.rename(columns={'L': 'Loss', 'W': 'Wins'})\n",
        "  cities_teams_nfl = cities_teams_nfl.drop(['NFL', 'team'], axis=1)\n",
        "  cities_teams_nfl[['Population', 'Loss', 'Wins']] = cities_teams_nfl[['Population', 'Loss', 'Wins']].apply(pd.to_numeric) \n",
        "  cities_teams_nfl['Win ratio'] = cities_teams_nfl['Wins'] / (cities_teams_nfl['Wins'] + cities_teams_nfl['Loss'])\n",
        "  cities_teams_nfl = cities_teams_nfl.groupby('Metropolitan area').apply(group_win_loss_ratio)\n",
        "  cities_teams_nfl = cities_teams_nfl.drop_duplicates(subset='Metropolitan area', keep='first')\n",
        "  cities_teams_nfl = cities_teams_nfl.sort_values('Metropolitan area')\n",
        "  cities_teams_nfl = cities_teams_nfl.reset_index(drop=True)\n",
        "\n",
        "  return cities_teams_nfl"
      ],
      "metadata": {
        "id": "A0nwYqxHpc7t"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nhl_correlation():\n",
        "  cities_teams_nhl = clean_nhl_df()\n",
        "\n",
        "  population_by_region = list(cities_teams_nhl['Population']) \n",
        "  win_loss_by_region = list(cities_teams_nhl['Win ratio']) \n",
        "\n",
        "  return stats.pearsonr(population_by_region, win_loss_by_region)[0]"
      ],
      "metadata": {
        "id": "XvRDD9GeqOqq"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nba_correlation():\n",
        "  cities_teams_nba = clean_nba_df()\n",
        "\n",
        "  population_by_region = list(cities_teams_nba['Population']) \n",
        "  win_loss_by_region = list(cities_teams_nba['Win ratio']) \n",
        "\n",
        "  return stats.pearsonr(population_by_region, win_loss_by_region)[0]"
      ],
      "metadata": {
        "id": "GKfVeKk6p-WT"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mlb_correlation():\n",
        "  cities_teams_mlb = clean_mlb_df()\n",
        "\n",
        "  population_by_region = list(cities_teams_mlb['Population']) \n",
        "  win_loss_by_region = list(cities_teams_mlb['Win ratio']) \n",
        "\n",
        "  return stats.pearsonr(population_by_region, win_loss_by_region)[0]"
      ],
      "metadata": {
        "id": "IkNMv6j-qZLY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nfl_correlation():\n",
        "  cities_teams_nfl = clean_nfl_df()\n",
        "\n",
        "  population_by_region = list(cities_teams_nfl['Population']) \n",
        "  win_loss_by_region = list(cities_teams_nfl['Win ratio']) \n",
        "\n",
        "  return stats.pearsonr(population_by_region, win_loss_by_region)[0]"
      ],
      "metadata": {
        "id": "u9T9yjHHqfwY"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nhl_correlation()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBkBYdcsqn03",
        "outputId": "6aa04aa4-c3c8-46e3-af07-4ce6783aaaa5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-6004683283bc>:29: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
            "To preserve the previous behavior, use\n",
            "\n",
            "\t>>> .groupby(..., group_keys=False)\n",
            "\n",
            "To adopt the future behavior and silence this warning, use \n",
            "\n",
            "\t>>> .groupby(..., group_keys=True)\n",
            "  cities_teams_nhl = cities_teams_nhl.groupby('Metropolitan area').apply(group_win_loss_ratio)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.012486162921209923"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nba_correlation()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkDrunkaqpgH",
        "outputId": "95a9a81b-5300-471e-96ef-291723734b82"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-0cb7acdadc4a>:28: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
            "To preserve the previous behavior, use\n",
            "\n",
            "\t>>> .groupby(..., group_keys=False)\n",
            "\n",
            "To adopt the future behavior and silence this warning, use \n",
            "\n",
            "\t>>> .groupby(..., group_keys=True)\n",
            "  cities_teams_nba = cities_teams_nba.groupby('Metropolitan area').apply(group_win_loss_ratio)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.17657160252844614"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlb_correlation()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mjqFFZPqq_3",
        "outputId": "e2c6588e-3437-4e3d-cecd-018b2423767c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-9c96ced8dfd3>:29: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
            "To preserve the previous behavior, use\n",
            "\n",
            "\t>>> .groupby(..., group_keys=False)\n",
            "\n",
            "To adopt the future behavior and silence this warning, use \n",
            "\n",
            "\t>>> .groupby(..., group_keys=True)\n",
            "  cities_teams_mlb = cities_teams_mlb.groupby('Metropolitan area').apply(group_win_loss_ratio)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.15027698302669307"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nfl_correlation()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knLkXbxRqsUX",
        "outputId": "8dc30203-b322-42ac-9b9b-36ae96156de0"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-c6c3f8d579a2>:30: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
            "To preserve the previous behavior, use\n",
            "\n",
            "\t>>> .groupby(..., group_keys=False)\n",
            "\n",
            "To adopt the future behavior and silence this warning, use \n",
            "\n",
            "\t>>> .groupby(..., group_keys=True)\n",
            "  cities_teams_nfl = cities_teams_nfl.groupby('Metropolitan area').apply(group_win_loss_ratio)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.004922112149349409"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ]
}